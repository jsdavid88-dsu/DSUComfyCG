{
    "models": {
        "Wan2_2-S2V-14B_fp8_e4m3fn_scaled_KJ.safetensors": {
            "url": "https://huggingface.co/Kijai/WanVideo_comfy_fp8_scaled/resolve/main/wan2_2/Wan2_2-S2V-14B_fp8_e4m3fn_scaled_KJ.safetensors",
            "folder": "diffusion_models",
            "size": "14.3GB",
            "description": "Wan 2.2 Sound-to-Video 14B FP8 model"
        },
        "Wan2_2-Animate-14B_fp8_e4m3fn_scaled_KJ.safetensors": {
            "url": "https://huggingface.co/Kijai/WanVideo_comfy_fp8_scaled/resolve/main/Wan2_2-Animate-14B_fp8_e4m3fn_scaled_KJ.safetensors",
            "folder": "diffusion_models",
            "size": "14.3GB",
            "description": "Wan 2.2 Animate 14B FP8 model"
        },
        "Wan2_1_mocha-14B-preview_fp8_e4m3fn_scaled_KJ.safetensors": {
            "url": "https://huggingface.co/Kijai/WanVideo_comfy_fp8_scaled/resolve/main/MoCha/Wan2_1_mocha-14B-preview_fp8_e4m3fn_scaled_KJ.safetensors",
            "folder": "diffusion_models",
            "size": "14.3GB",
            "description": "Wan 2.1 MoCha 14B Preview FP8 model"
        },
        "Wan2_1_VAE_bf16.safetensors": {
            "url": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1_VAE_bf16.safetensors",
            "folder": "vae",
            "size": "800MB",
            "description": "Wan 2.1 VAE BF16"
        },
        "wan_2.1_vae.safetensors": {
            "url": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1_VAE_bf16.safetensors",
            "folder": "vae",
            "size": "800MB",
            "description": "Wan 2.1 VAE (alias)"
        },
        "umt5-xxl-enc-bf16.safetensors": {
            "url": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/umt5-xxl-enc-bf16.safetensors",
            "folder": "clip",
            "size": "12GB",
            "description": "UMT5-XXL Encoder BF16"
        },
        "umt5_xxl_fp16.safetensors": {
            "url": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/umt5-xxl-enc-bf16.safetensors",
            "folder": "clip",
            "size": "12GB",
            "description": "UMT5-XXL FP16 (alias)"
        },
        "umt5-xxl-enc-fp8_e4m3fn.safetensors": {
            "url": "https://huggingface.co/Kijai/WanVideo_comfy_fp8_scaled/resolve/main/umt5-xxl-enc-fp8_e4m3fn.safetensors",
            "folder": "clip",
            "size": "5GB",
            "description": "UMT5-XXL Encoder FP8"
        },
        "clip_vision_h.safetensors": {
            "url": "https://huggingface.co/Comfy-Org/clip_vision_h/resolve/main/clip_vision_h.safetensors",
            "folder": "clip_vision",
            "size": "2.5GB",
            "description": "CLIP Vision H"
        },
        "WanAnimate_relight_lora_fp16.safetensors": {
            "url": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/loras/WanAnimate_relight_lora_fp16.safetensors",
            "folder": "loras",
            "size": "500MB",
            "description": "Wan Animate Relight LoRA"
        },
        "lightx2v_I2V_14B_480p_cfg_step_distill_rank64_bf16.safetensors": {
            "url": "https://huggingface.co/Lightricks/LTX-Video/resolve/main/loras/lightx2v_I2V_14B_480p_cfg_step_distill_rank64_bf16.safetensors",
            "folder": "loras",
            "size": "600MB",
            "description": "LightX2V I2V 14B LoRA"
        },
        "lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank64_bf16.safetensors": {
            "url": "https://huggingface.co/Lightricks/LTX-Video/resolve/main/loras/lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank64_bf16.safetensors",
            "folder": "loras",
            "size": "600MB",
            "description": "LightX2V T2V 14B LoRA"
        },
        "ltx_video_v2.safetensors": {
            "url": "https://huggingface.co/Lightricks/LTX-Video/resolve/main/ltx-video-2b.safetensors",
            "folder": "checkpoints",
            "size": "9GB",
            "description": "LTX Video v2"
        },
        "sam2.1_hiera_base_plus.safetensors": {
            "url": "https://huggingface.co/facebook/sam2-hiera-base-plus/resolve/main/sam2.1_hiera_base_plus.safetensors",
            "folder": "sam2",
            "size": "400MB",
            "description": "SAM2 Hiera Base Plus"
        },
        "qwen_2.5_vl_7b_fp8_scaled.safetensors": {
            "url": "https://huggingface.co/Kijai/Qwen2-VL-7B-Instruct_fp8_scaled/resolve/main/qwen2-vl-7b-instruct_fp8_scaled.safetensors",
            "folder": "LLM",
            "size": "8GB",
            "description": "Qwen 2.5 VL 7B FP8"
        },
        "qwen_image_edit_2509_fp8_e4m3fn.safetensors": {
            "url": "https://huggingface.co/Kijai/flux-fp8/resolve/main/qwen_image_edit_2509_fp8_e4m3fn.safetensors",
            "folder": "LLM",
            "size": "8GB",
            "description": "Qwen Image Edit FP8"
        },
        "qwen_image_vae.safetensors": {
            "url": "https://huggingface.co/Kijai/flux-fp8/resolve/main/qwen_image_vae.safetensors",
            "folder": "vae",
            "size": "200MB",
            "description": "Qwen Image VAE"
        },
        "Qwen-Image-Lightning-4steps-V2.0-bf16.safetensors": {
            "url": "https://huggingface.co/Kijai/flux-fp8/resolve/main/Qwen-Image-Lightning-4steps-V2.0-bf16.safetensors",
            "folder": "diffusion_models",
            "size": "12GB",
            "description": "Qwen Image Lightning 4-step"
        },
        "MelBandRoformer_fp32.safetensors": {
            "url": "https://huggingface.co/Kijai/MelBand-Roformer/resolve/main/MelBandRoformer_fp32.safetensors",
            "folder": "audio",
            "size": "300MB",
            "description": "MelBand Roformer Audio Separator"
        },
        "wav2vec2_large_english_fp16.safetensors": {
            "url": "https://huggingface.co/facebook/wav2vec2-large-robust/resolve/main/model.safetensors",
            "folder": "audio",
            "size": "1.2GB",
            "description": "Wav2Vec2 Large English"
        },
        "rife47.pth": {
            "url": "https://huggingface.co/Kijai/RIFE_fp16/resolve/main/rife47.pth",
            "folder": "rife",
            "size": "25MB",
            "description": "RIFE 4.7 Frame Interpolation"
        },
        "yolox_l.torchscript.pt": {
            "url": "https://huggingface.co/yzd-v/DWPose/resolve/main/yolox_l.torchscript.pt",
            "folder": "yolo",
            "size": "200MB",
            "description": "YOLOX-L Object Detection"
        },
        "dw-ll_ucoco_384_bs5.torchscript.pt": {
            "url": "https://huggingface.co/yzd-v/DWPose/resolve/main/dw-ll_ucoco_384_bs5.torchscript.pt",
            "folder": "dwpose",
            "size": "350MB",
            "description": "DW-LL UCoCo Pose Detection"
        },
        "sd_xl_base_1.0.safetensors": {
            "url": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors",
            "folder": "checkpoints",
            "size": "6.94GB",
            "description": "SDXL Base 1.0"
        },
        "Wan2.2-S2V-14B-Q4_K_M.gguf": {
            "url": "https://huggingface.co/city96/Wan2.2-S2V-14B-gguf/resolve/main/Wan2.2-S2V-14B-Q4_K_M.gguf",
            "folder": "diffusion_models",
            "size": "8GB",
            "description": "Wan 2.2 S2V 14B GGUF Q4"
        }
    },
    "folder_mappings": {
        "diffusion_models": "ComfyUI/models/diffusion_models",
        "checkpoints": "ComfyUI/models/checkpoints",
        "vae": "ComfyUI/models/vae",
        "clip": "ComfyUI/models/clip",
        "clip_vision": "ComfyUI/models/clip_vision",
        "loras": "ComfyUI/models/loras",
        "sam2": "ComfyUI/models/sam2",
        "LLM": "ComfyUI/models/LLM",
        "audio": "ComfyUI/models/audio",
        "rife": "ComfyUI/models/rife",
        "yolo": "ComfyUI/models/yolo",
        "dwpose": "ComfyUI/models/dwpose"
    }
}